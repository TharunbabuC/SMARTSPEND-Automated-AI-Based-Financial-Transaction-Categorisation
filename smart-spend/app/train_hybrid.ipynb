{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0163ebae",
   "metadata": {},
   "source": [
    "app/train_hybrid.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68379425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33370f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(__file__).resolve().parents[1]\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "MODEL_DIR = BASE_DIR / \"saved_model\"\n",
    "CONFIG_DIR = BASE_DIR / \"config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f3352",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "DATASET = DATA_DIR / \"transactions.csv\"\n",
    "FEEDBACK = DATA_DIR / \"feedback.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd1b61",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    print(\"‚è≥ Training model...\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load main dataset\n",
    "    # -----------------------------\n",
    "    df = pd.read_csv(DATASET)\n",
    "\n",
    "    # Add feedback data if exists\n",
    "    if FEEDBACK.exists():\n",
    "        fb = pd.read_csv(FEEDBACK)\n",
    "        fb.columns = [\"merchant\", \"model_prediction\", \"correct_category\"]\n",
    "        fb = fb.rename(columns={\"correct_category\": \"category\"})\n",
    "        df = pd.concat([df, fb[[\"merchant\", \"category\"]]], ignore_index=True)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    X = df[\"merchant\"].astype(str)\n",
    "    y = df[\"category\"].astype(str)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Vectorizer (word + char)\n",
    "    # -----------------------------\n",
    "    word_tfidf = (\"word\", TfidfVectorizer(\n",
    "        analyzer=\"word\",\n",
    "        ngram_range=(1,2),\n",
    "        min_df=3,\n",
    "        stop_words=\"english\"\n",
    "    ))\n",
    "\n",
    "    char_tfidf = (\"char\", TfidfVectorizer(\n",
    "        analyzer=\"char_wb\",\n",
    "        ngram_range=(3,5),\n",
    "        min_df=3\n",
    "    ))\n",
    "\n",
    "    vectorizer = FeatureUnion([word_tfidf, char_tfidf])\n",
    "    X_vec = vectorizer.fit_transform(X)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Model = Linear SVM + Prob Calibrator\n",
    "    # -----------------------------\n",
    "    base = LinearSVC(max_iter=20000)\n",
    "    model = CalibratedClassifierCV(base, method=\"sigmoid\", cv=4)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_vec, y,\n",
    "        test_size=0.15,\n",
    "        stratify=y,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_val)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Print metrics in terminal\n",
    "    # -----------------------------\n",
    "    val_acc = accuracy_score(y_val, pred)\n",
    "    print(\"\\nüìä Validation accuracy:\", val_acc)\n",
    "    print(classification_report(y_val, pred))\n",
    "\n",
    "    # -----------------------------\n",
    "    # SAVE MODEL + VECTORIZER\n",
    "    # -----------------------------\n",
    "    MODEL_DIR.mkdir(exist_ok=True)\n",
    "    joblib.dump(model, MODEL_DIR / \"svm_model.pkl\")\n",
    "    joblib.dump(vectorizer, MODEL_DIR / \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save taxonomy\n",
    "    # -----------------------------\n",
    "    taxonomy = {\"categories\": sorted(list(model.classes_))}\n",
    "    with open(CONFIG_DIR / \"taxonomy.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(taxonomy, f, indent=2)\n",
    "\n",
    "    # -----------------------------\n",
    "    # SAVE METRICS FOR STREAMLIT DASHBOARD\n",
    "    # -----------------------------\n",
    "    cm = confusion_matrix(y_val, pred)\n",
    "    report = classification_report(y_val, pred, output_dict=True)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": float(val_acc),\n",
    "        \"report\": report,\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"classes\": taxonomy[\"categories\"]\n",
    "    }\n",
    "\n",
    "    with open(CONFIG_DIR / \"model_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    print(\"üìÅ Saved evaluation to config/model_metrics.json\")\n",
    "    print(\"‚úî Training completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
